{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import random\n",
    "import pickle #save results\n",
    "from itertools import chain\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from shapely import MultiLineString\n",
    "from shapely import Point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1, Read Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1, Raod Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "road = gpd.read_file('data/Road_Cleaned.shp')\n",
    "road.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2, Demographic data (Census Tract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = gpd.read_file('data/Erie_County_Census_Tract.shp')#.set_index('GEOID10')\n",
    "#check size of census track data\n",
    "len(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3, Commute Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#od = pd.read_csv('Data/tract-od.csv.zip',dtype={i:(str if i<2 else int) for i in range(6)})\n",
    "#od = pd.read_csv('Data/tract-od_2019.csv')\n",
    "#od = pd.read_csv('Data/tract-od_2019_temp.csv',dtype={i:(str if i<2 else int) for i in range(6)})\n",
    "od = pd.read_csv('data/erie-tract-od.csv')\n",
    "#od = pd.read_csv('Data/ny-tract-od.csv')\n",
    "od = od.astype({\"work\": str, \"home\": str})\n",
    "od.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od[(od.work == '36029000110') & od.home.str.startswith('36029')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(od)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4, Workplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbp = pd.read_csv('data/CBP2020/CBP2020.CB2000CBP-Data.csv')#.iloc[1:,[0,9,11]]\n",
    "cbp = cbp[cbp['EMPSZES_LABEL'] == 'All establishments'].copy()\n",
    "cbp['county'] = cbp.GEO_ID.astype(str).str[-5:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cbp.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "county_com_total = cbp[cbp['NAICS2017'] == '00'].reset_index(drop=True).copy()\n",
    "len(county_com_total)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "county_com_total.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2, Data PreProcessing\n",
    "#### Add 3 columns on dp (demographics) dataframe\n",
    "* [col1] controls the number of individuals will be generated within each census tract\n",
    "* [col2] the number of workplaces\n",
    "* [col3] the probability for employees(individuals) to be assigned in each workplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 The number of workplaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_wp(data, od, cbp):\n",
    "    \"\"\"\n",
    "    calculate number of workplaces for each tract\n",
    "    wp_tract = wp_cty * (tract_employed / county_employed)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        \"\"\"\n",
    "        calculate number of workplaces for each tract\n",
    "        wp_tract = wp_cty * (tract_employed / county_employed)\n",
    "        \"\"\"\n",
    "\n",
    "        #print(\"++++++++++\")\n",
    "        # use \"od data\" to get number of jobs in each census tract\n",
    "        # and number of jobs in each county\n",
    "        tract_number = data.GEOID10#.astype(int)\n",
    "        tract_jobs_df = od[['work','S000']].groupby('work').sum().reset_index()\n",
    "        tract_jobs_df = tract_jobs_df.astype({\"work\": str})\n",
    "        tract_jobs_number = int(tract_jobs_df.loc[tract_jobs_df.work == tract_number, 'S000'].values[0]) # total number of job in each tract\n",
    "        #print(\"Tract\", tract_number, \"has\", tract_jobs_number, \"jobs\")\n",
    "\n",
    "        #county total number of job\n",
    "        county_number = tract_number[:5]\n",
    "        tract_jobs_df['county'] = tract_jobs_df.work.astype(str).str[:5]\n",
    "        county_job_df = tract_jobs_df[['county','S000']].groupby('county').sum().reset_index()\n",
    "        county_job_number = int(county_job_df.S000[0])\n",
    "        #print(\"County\", county_number, \"has\", county_job_number, \"jobs\")\n",
    "        #print(\"++++++++++\")\n",
    "\n",
    "        #use company number\n",
    "        #county wrk place establishment number\n",
    "        #cbp['county'] = cbp.GEO_ID.astype(str).str[-5:]\n",
    "        #print(\"==========\")\n",
    "        campany_df = cbp.loc[:,['county', 'NAME', 'ESTAB']]\n",
    "        county_campany_number = int(campany_df[campany_df.county == county_number].ESTAB.values[0])\n",
    "        #print(\"County\", county_number, \"has\", county_campany_number, \"company\")\n",
    "\n",
    "        tract_wp_number = int(county_campany_number * (tract_jobs_number / county_job_number))\n",
    "\n",
    "        #print(\"Tract\",  tract_number, \"has\", tract_wp_number, \"companys\")\n",
    "        return tract_wp_number\n",
    "    except:\n",
    "        print(tract_number, \"has issue\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3, The probability for employees(individuals) to be assigned in each workplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wp_proba(x):\n",
    "    \"\"\"\n",
    "    probability of an employee working in that workplace is lognormal:\n",
    "    http://www.haas.berkeley.edu/faculty/pdf/wallace_dynamics.pdf\n",
    "    \"\"\"\n",
    "    if x == 0: return np.zeros(0)\n",
    "    b = np.random.lognormal(mean=2,size=x).reshape(-1, 1)\n",
    "    return np.sort(normalize(b,norm='l1',axis=0).ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Apply Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "#This will ignore all DeprecationWarning warnings in your code.\n",
    "dp['WP_CNT'] = dp.apply(number_of_wp, args=(od, county_com_total),axis=1)\n",
    "dp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dp.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.to_file('data/Erie_Tracts_with_Work.shp', driver = \"ESRI Shapefile\")\n",
    "dp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#dp = gpd.read_file('Data/Erie_Tracts_with_Work.shp')\n",
    "dp = gpd.read_file('data/fairfax2010-complete.shp')\n",
    "dp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dp.iloc[:,23:59]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dp.iloc[:,154:169]"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each track, the probability distribution for an employee to work there is lognormal\n",
    "# this column has the probability for each workplace and they add up to 1. \n",
    "dp['WP_PROBA'] = dp.WP_CNT.map(wp_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.sort_index(axis=1,inplace=True)\n",
    "#dp.sort_values(by = 'GEOID10')\n",
    "dp = dp.set_index('GEOID10')\n",
    "dp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3, Synthesizing Population "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3,1 Create individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_individuals(tract):\n",
    "    #print(\"++++++++++Create People+++++++++++\")\n",
    "    \"\"\"Generate a population of ages and sexes as a DataFrame\n",
    "\n",
    "    Given the number of individuals for 18 age groups of each sex,\n",
    "    return a two column DataFrame of age ([0,89]) and sex ('m','f')\n",
    "    \"\"\"\n",
    "    #portion = tract.geometry.area / tract.Shape_Area # what portion of the tract is included\n",
    "    #age_sex_groups = (tract[22:59].drop('DP0010039') * portion).astype(int)\n",
    "    \n",
    "    age_sex_groups = (tract[22:59].drop('DP0010039')).astype(int)\n",
    "    \n",
    "    #dfs=pd.DataFrame()\n",
    "    dfs = []\n",
    "    \n",
    "    #code is the index(generated by the enumerate build-in function) of the list \n",
    "    #,which indicates the age and sex group\n",
    "    #code 0~17 male\n",
    "    #code 18~35 female\n",
    "    for code,count in enumerate(age_sex_groups):\n",
    "        base_age = (code % 18)*5\n",
    "        gender = 'm' if code < 18 else 'f'\n",
    "        ages = []\n",
    "        for offset in range(4):\n",
    "            ages.extend([offset+base_age]*(count//5))\n",
    "        ages.extend([base_age+4]*(count-len(ages)))\n",
    "        temp = pd.DataFrame({'code':code, 'age':ages,'sex':[gender]*count})\n",
    "        dfs.append(pd.DataFrame({'code':code, 'age':ages,'sex':[gender]*count}))\n",
    "        #dfs = pd.concat([dfs, temp])\n",
    "    df = pd.concat(dfs).sample(frac=1,random_state=123).reset_index(drop=True)\n",
    "    #df = pd.concat([dfs]).sample(frac=1,random_state=123).reset_index(drop=True)\n",
    "    df.index = tract.name + 'i' + df.index.to_series().astype(str)\n",
    "    #df['friends'] = [set()] * len(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Create households"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_households(tract, people):\n",
    "    #print(\"++++++++++Create Hhold+++++++++++\")\n",
    "    #get the amount of each household type (GOOD)\n",
    "    hh_cnt = get_hh_cnts(tract)\n",
    "    #print(hh_cnt)\n",
    "    \n",
    "    #create a empty df to hold indivadual hhold \n",
    "    hholds = pd.DataFrame()\n",
    "    \n",
    "    #create a column to in hhold to hold the households types info\n",
    "    hholds['htype'] = np.repeat(hh_cnt.index,hh_cnt)\n",
    "    #print(hholds[hholds.htype == 6])\n",
    "    #hholds = hholds[hholds.htype != 6].sort_values('htype',ascending=False).concat(hholds[hholds.htype == 6])\n",
    "    #hholds = hholds[hholds.htype != 6].sort_values('htype',ascending=False).append(hholds[hholds.htype == 6])\n",
    "    \n",
    "    temp1 = hholds[hholds.htype != 6].sort_values('htype',ascending=False)\n",
    "    #print(temp1)\n",
    "    temp2 = hholds[hholds.htype == 6]\n",
    "    #print(temp2)\n",
    "    hholds = pd.concat([temp1, temp2])#.sort_values('htype',ascending=False)\n",
    "    #print(hholds)\n",
    "    #create member for each households; \n",
    "    #for remaining populating, populate them in households as relatives and those living in group quarter (non-household)\n",
    "    populate_households(tract, people, hholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the number of household under different household types\n",
    "def get_hh_cnts(tract):\n",
    "    \"\"\"\n",
    "    Eleven household types:\n",
    "    0         h&w (no<18)\n",
    "    1      h&w&ch (ch<18)\n",
    "    2        male (no<18)\n",
    "    3        male (ch<18)\n",
    "    4      female (no<18)\n",
    "    5      female (ch<18)\n",
    "    6     nonfamily group\n",
    "    7       lone male <65\n",
    "    8       lone male >65\n",
    "    9      lone female<65\n",
    "    10     lone female>65\n",
    "    \"\"\"\n",
    "\n",
    "    householdConstraints = (tract[150:166]).astype(int) #HOUSEHOLDS BY TYPE\n",
    "    #print(householdConstraints.head())\n",
    "    hh_cnt = pd.Series(np.zeros(11),dtype=int) #11 household types (group quarters are not household)\n",
    "\n",
    "    # husband/wife families\n",
    "    # husband-wife family DP0130004 - DP0130005: Husband-wife family - With own children under 18 years\n",
    "    hh_cnt[0] = householdConstraints[4] - householdConstraints[5]; \n",
    "    # husband-wife family DP0130005, OWN CHILDREN < 18\n",
    "    hh_cnt[1] = householdConstraints[5]; \n",
    "    \n",
    "    # male householders\n",
    "    # single male householder DP0130006 - DP0130007: Male householder, no wife present - Male householder, no wife present\n",
    "    hh_cnt[2] = householdConstraints[6] - householdConstraints[7]; \n",
    "    # single male householder DP0130007, OWN CHILDREN < 18\n",
    "    hh_cnt[3] = householdConstraints[7];\n",
    "    \n",
    "    # female householders\n",
    "    # single female householder DP0130008 - DP0130009: Female householder, no husband present - With own children under 18 years\n",
    "    \n",
    "    # single female householder DP0130009, OWN CHILDREN < 18\n",
    "    hh_cnt[4] = householdConstraints[8] - householdConstraints[9]; # single female householder\n",
    "    hh_cnt[5] = householdConstraints[9]; # single female householder, OWN CHILDREN < 18\n",
    "    \n",
    "    \n",
    "    # nonfamily householder\n",
    "    hh_cnt[6] = householdConstraints[10] - householdConstraints[11]; # nonfamily group living\n",
    "    hh_cnt[7] = householdConstraints[12] - householdConstraints[13]; # lone male < 65\n",
    "    hh_cnt[8] = householdConstraints[13]; # lone male >= 65\n",
    "    hh_cnt[9] = householdConstraints[14] - householdConstraints[15]; # lone female < 65\n",
    "    hh_cnt[10] = householdConstraints[15]; # lone female >= 65\n",
    "\n",
    "    return hh_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate household members based on hhold type\n",
    "def gen_households(hh_type, people, mask):\n",
    "    \"\"\"\n",
    "    Eleven household types:\n",
    "    0         h&w (no<18) husband and wife no kids\n",
    "    1      h&w&ch (ch<18) husband and wife with kids\n",
    "    2        male (no<18) male with no kids (wife not present)\n",
    "    3        male (ch<18) male with kids (wife not present)\n",
    "    4      female (no<18) female with no kids (husband not present)\n",
    "    5      female (ch<18) female with kids (husband not present) \n",
    "    6     nonfamily group \n",
    "    7       lone male <65 male younger than 65 lives alone \n",
    "    8       lone male >65 male older than 65 lives alone\n",
    "    9      lone female<65 female younger than 65 lives alone\n",
    "    10     lone female>65 female older than 65 lives alone\n",
    "    \"\"\"\n",
    "    #create a list to hold household member\n",
    "    members = []\n",
    "    \n",
    "\n",
    "    #first, create household head, 11 types\n",
    "    #age range of the householder for each household type  (the range comes from dp age range above)\n",
    "    head_ranges = [\n",
    "                    range(4,18), range(4,14), range(4,18), range(4,14),range(22,36), range(22,30),\n",
    "                    #6\n",
    "                    chain(range(4,18),range(21,36)),  \n",
    "                    range(4,13), range(13,18), range(21,31), range(31,36)\n",
    "                  ]\n",
    " \n",
    "    '''\n",
    "        meaning of the head_ranges: \n",
    "        [(15,99)/m/hh0,(20,70)/m/hh1,(15,99)/m/hh2,(20,70)/m/hh3,(15,99)/f/hh0,(20,70)/f/hh1,\n",
    "        (15,99)/f/hh4,(15,65)/f/hh5,(20,65)/m/hh7,(65,99)/m/hh8,(15,65)/f/hh9,(65,99)/f/hh10]\n",
    "        \n",
    "        head_sex:\n",
    "        [(1'm'),(2'm'),(3'm'),(4'm'),(5'f'),(6'f'),(7'f'),(8'f'),(9'm'),(10'm'),(11'f'),(12'f')]\n",
    "\n",
    "    ''' \n",
    "    #add the householder\n",
    "    pot = people[mask].code #potential's age or age group\n",
    "    \n",
    "    #selcet households head\n",
    "    iindex = pot[pot.isin(head_ranges[hh_type])].index[0] #potential's age is in the range of this hh type\n",
    "    # what is hh_type\n",
    "    \n",
    "    h1 = people.loc[iindex] #age & sex of h1, what is h1\n",
    "    \n",
    "    mask[iindex] = False\n",
    "    members.append(iindex)\n",
    "\n",
    "    #if living alone then return the members\n",
    "    if hh_type > 6:\n",
    "        return members\n",
    "\n",
    "    #if husband and wife, add the wife\n",
    "    if hh_type in (0,1):\n",
    "        pot = people[mask].code\n",
    "        if h1.code == 4: #if husband is 20~24\n",
    "            iindex = pot[pot.isin(range(h1.code+17,h1.code+20))].index[0] #wife is -4~14 + husband age\n",
    "        else: # if husband is older than 20~24\n",
    "            iindex = pot[pot.isin(range(h1.code+16,h1.code+20))].index[0] \n",
    "        \n",
    "        h2 = people.loc[iindex] # -4 < husband.age - wife.age < 9\n",
    "        mask[iindex] = False\n",
    "        members.append(iindex)\n",
    "\n",
    "\n",
    "    \"\"\"A child includes a son or daughter by birth (biological child), a stepchild,\n",
    "    or an adopted child of the householder, regardless of the childâ€™s age or marital status.\n",
    "    The category excludes sons-in-law, daughters- in-law, and foster children.\"\"\"\n",
    "    #household types with at least one child (18-)\n",
    "    if hh_type in (1,3,5):\n",
    "        #https://www.census.gov/hhes/families/files/graphics/FM-3.pdf\n",
    "        if hh_type == 1:\n",
    "            num_of_child = max(1,abs(int(np.random.normal(2)))) #gaussian touch\n",
    "        elif hh_type == 3:\n",
    "            num_of_child = max(1,abs(int(np.random.normal(1.6)))) #gaussian touch\n",
    "        elif hh_type == 5:\n",
    "            num_of_child = max(1,abs(int(np.random.normal(1.8)))) #gaussian touch\n",
    "\n",
    "        pot = people[mask]\n",
    "        if hh_type == 1:\n",
    "            iindices = pot[(pot.age<18) & (45 > h2.age-pot.age)].index[:num_of_child]\n",
    "        else: #father (mother) and child age difference not to exceed 50 (40)\n",
    "            age_diff = 45 if hh_type == 5 else 55\n",
    "            iindices = pot[(pot.age<18) & (age_diff>h1.age-pot.age)].index[:num_of_child]\n",
    "        \n",
    "        for i in iindices:\n",
    "            child = people.loc[i]\n",
    "            mask[i] = False\n",
    "            members.append(i)\n",
    "\n",
    "    #if nonfamily group then either friends or unmarried couples\n",
    "    if hh_type == 6:\n",
    "        pot = people[mask].code\n",
    "        num_of_friends = max(1,abs(int(np.random.normal(1.3)))) #gaussian touch\n",
    "        iindices = pot[pot.isin(range(h1.code-2,h1.code+3))].index[:num_of_friends]\n",
    "        for i in iindices:\n",
    "            friend = people.loc[i]\n",
    "            mask[i] = False\n",
    "            members.append(i)\n",
    "\n",
    "    return members\n",
    "\n",
    "\n",
    "def populate_households(tract, people, hholds):\n",
    "    \n",
    "    #What is the mask for?\n",
    "    mask = pd.Series(True, index = people.index) #[True]*len(people)\n",
    "    \n",
    "    hholds['members'] = hholds.htype.apply(gen_households,args=(people, mask,))\n",
    "    \n",
    "    \"\"\"The seven types of group quarters are categorized as institutional group quarters\n",
    "    (correctional facilities for adults, juvenile facilities, nursing facilities/skilled-nursing facilities,\n",
    "    and other institutional facilities) or noninstitutional group quarters (college/university student housing,\n",
    "    military quarters, and other noninstitutional facilities).\"\"\"\n",
    "    \n",
    "    group_population = int(tract.DP0120014) #people living in group quarters (not in households)\n",
    "    \n",
    "    #gq_indices = people[(people.age>=65) | (people.age<18)].index[:group_population]\n",
    "    gq_indices = people[mask].index[:group_population]\n",
    "    \n",
    "    #for i in gq_indices: mask[i] = False\n",
    "    mask.loc[gq_indices] = False\n",
    "\n",
    "    #now distribute the remaining household guys as relatives...\n",
    "    relatives = people[mask].index\n",
    "    it = iter(relatives) #sample by replacement\n",
    "    relative_hhs = hholds[hholds.htype<7].sample(n=len(relatives),replace=True)\n",
    "    relative_hhs.members.apply(lambda x: x.append(next(it))) #appends on mutable lists\n",
    "    #for i in relatives: mask[i] = False\n",
    "    mask.loc[relatives]= False\n",
    "    #print('is anyone left homeless:',any(mask))\n",
    "    #add those living in group quarters as all living in a house of 12th type\n",
    "    if group_population > 0:\n",
    "        hholds.loc[len(hholds)] = {'htype':11, 'members':gq_indices}\n",
    "    \n",
    "    # name households\n",
    "    hholds = hholds.set_index(tract.name+'h'+pd.Series(np.arange(len(hholds)).astype(str)))\n",
    "\n",
    "    ## where is hh???\n",
    "    def hh_2_people(hh,people):\n",
    "        for m in hh.members:\n",
    "            people.loc[m,'hhold'] = hh.name\n",
    "            people.loc[m,'htype'] = hh.htype\n",
    "    \n",
    "    hholds.apply(hh_2_people,args=(people,),axis=1)\n",
    "    people['htype'] = people.htype.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Assign workplaces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_workplaces(tract, people, od):\n",
    "    #print(\"++++++++++Assigning Work+++++++++++\")\n",
    "    \"\"\"\n",
    "    if the destination tract of a worker is not in our DP dataset\n",
    "    then we assign his wp to 'DTIDw', otherwise 'DTIDw#'\n",
    "    \n",
    "    the actual size distribution of establishments is lognormal\n",
    "    https://www.princeton.edu/~erossi/fsdae.pdf\n",
    "    \"\"\"\n",
    "    #destination tracts and numbers\n",
    "    #print(\"tract number is\",tract.name, type(tract.name))\n",
    "    td = od[od['home'] == tract.name].set_index('work').S000\n",
    "    \n",
    "    td = td.apply(np.ceil).astype(int) #from this tract to others\n",
    "    # 58.5%: US population (16+) - employment rate\n",
    "    # https://data.bls.gov/timeseries/LNS12300000\n",
    "    employed = people[people.age>=18].sample(td.sum()).index #get the employed\n",
    "    dtract = pd.Series(np.repeat(td.index.values, td.values)) #get the destination tract\n",
    "    # if 'wp' in people.columns: people.drop('wp',axis=1,inplace=True)\n",
    "    people.loc[employed,'wp'] = dtract.apply(lambda x: x+'w'+str(np.random.choice(dp.loc[x,'WP_CNT'],p=dp.loc[x,'WP_PROBA'])) if x in dp.index else x+'w').values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4, Get errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_errors(tract,people):\n",
    "    \"\"\"Percentage errors\"\"\"\n",
    "    err = {}    \n",
    "    #portion = tract.geometry.area / tract.Shape_Area # what portion of the tract is included\n",
    "    #senior_actual = int(tract.DP0150001 * portion) # Households with individuals 65 years and over\n",
    "    senior_actual = int(tract.DP0150001)\n",
    "    #minor_actual = int(tract.DP0140001 * portion) # Households with individuals under 18 years\n",
    "    minor_actual = int(tract.DP0140001)\n",
    "    #err['tract'] = tract.name\n",
    "    err['population'] = tract.DP0010001\n",
    "    err['in_gq'] = tract.DP0120014\n",
    "    avg_synthetic_family = people[people.htype<6].groupby('hhold').size().mean()\n",
    "    err['avg_family'] = 100*(avg_synthetic_family - tract.DP0170001) / tract.DP0170001\n",
    "    err['avg_hh'] = 100*(people[people.htype!=11].groupby('hhold').size().mean() - tract.DP0160001) / tract.DP0160001 \n",
    "    err['senior_hh'] = 100*(people[people.age>=65].hhold.nunique() - senior_actual) / senior_actual\n",
    "    err['minor_hh'] = 100*(people[people.age<18].hhold.nunique() - minor_actual) / minor_actual\n",
    "    return pd.Series(err,name=tract.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5, Create geo locations for each individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create space\n",
    "#shapely geometries are not hashable, here is my hash function to check the duplicates\n",
    "def hash_geom(g):\n",
    "    #print(\"Get the lat and long of the road segment and output to tuple\")\n",
    "    if g.geom_type == 'MultiLineString':\n",
    "        #print(\"MultiLineString\")\n",
    "        #print(g.geoms)\n",
    "        cord_list = []\n",
    "        for line in g.geoms:\n",
    "            for lat,lon in line.coords[:]:\n",
    "                #print((round(lat,6),round(lon,6)))\n",
    "                cord_list.append((round(lat,6),round(lon,6)))\n",
    "        #print(cord_list)\n",
    "        cord_tuple = tuple(item for item in cord_list)\n",
    "        #print(\"Tuple\")\n",
    "        #print(cord_tuple)\n",
    "        return tuple(item for item in cord_list)\n",
    "    else:\n",
    "        #print(\"Line\")\n",
    "        #print(tuple((round(lat,6),round(lon,6)) for lat,lon in g.coords[:]))\n",
    "        return tuple((round(lat,6),round(lon,6)) for lat,lon in g.coords[:]) #shaply older version\n",
    "        #return tuple((round(lat,6),round(lon,6)) for lat,lon in g.geoms) #shapely 2.0 or later version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_home_location(tract, hcnt, road):\n",
    "    #print(\"Creating House Space...\")\n",
    "    #create houses\n",
    "    if tract.DP0120014 > 0: hcnt += 1 #people living in group quarters (not in households)\n",
    "    \n",
    "    mask = road.intersects(tract.geometry) #get the road with in the census tract\n",
    "     #home road\n",
    "    hmask = mask & road.MTFCC.str.contains('S1400|S1740') #get the home road\n",
    "    hrd = road[hmask].intersection(tract.geometry)#get the geometry of home road\n",
    "    hrd = hrd[hrd.geom_type.isin(['LinearRing', 'LineString', 'MultiLineString'])]\n",
    "    hrd = hrd[~hrd.apply(hash_geom).duplicated()] #remove the duplicate lat and long by returning boolean Series denoting duplicate rows (using .duplicated()).\n",
    "\n",
    "    HD=0.0005\n",
    "    houses = hrd.apply(lambda x: pd.Series([x.interpolate(seg) for seg in np.arange(HD,x.length,HD)]))\n",
    "    #print(houses)\n",
    "    houses = houses.unstack().dropna().reset_index(drop=True) #flatten\n",
    "    houses = houses.sample(n=hcnt,replace=True).reset_index(drop=True)\n",
    "    houses.index = tract.name + 'h' + houses.index.to_series().astype(str)\n",
    "    \n",
    "    return gpd.GeoSeries(houses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#road[road.MTFCC == 'S1100'].head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_work_location(tract, road):\n",
    "    \n",
    "    #from shapely import MultiLineString, Point, ops, LineString\n",
    "    \n",
    "    WD=0.0002\n",
    "    \n",
    "    mask = road.intersects(tract.geometry) #get the road with in the census tract\n",
    "    \"\"\"\n",
    "        * Home Road\n",
    "        S1400 Local Neighborhood Road, Rural Road, City Street\n",
    "        S1740 Private Road for service vehicles (logging, oil fields, ranches, etc.) \n",
    "        * Work Road\n",
    "        S1100 Primary Road\n",
    "        S1200 Secondary Road\n",
    "    \"\"\"\n",
    "    #work road\n",
    "    wmask = mask & road.MTFCC.str.contains('S1100|S1200') #S1100 Primary Road; S1200 Secondary Road,\n",
    "    wrd = road[wmask].intersection(tract.geometry)#get the geometry of work road\n",
    "    wrd = wrd[wrd.geom_type.isin(['LinearRing', 'LineString', 'MultiLineString'])]\n",
    "    wrd = wrd[~wrd.apply(hash_geom).duplicated()] #remove the duplicate lat and long by returning boolean Series denoting duplicate rows (using .duplicated()).\n",
    "    \n",
    "    #home road\n",
    "    hmask = mask & road.MTFCC.str.contains('S1400|S1740') #get the home road\n",
    "    hrd = road[hmask].intersection(tract.geometry)#get the geometry of home road\n",
    "    hrd = hrd[hrd.geom_type.isin(['LinearRing', 'LineString', 'MultiLineString'])]\n",
    "    hrd = hrd[~hrd.apply(hash_geom).duplicated()] #remove the duplicate lat and long by returning boolean Series denoting duplicate rows (using .duplicated()).\n",
    "    \n",
    "    wrk_point = wrd.apply(lambda x: pd.Series([x.interpolate(seg) for seg in np.arange(WD, x.length,WD)]))#Get the workplace loaction point on each road segment\n",
    "    #print(wrk_point)\n",
    "    #workplaces on the intersection of home roads with types S1400|S1740\n",
    "    #rwps = hrd.apply(lambda x: Point(x.coords[0]) if type(x) != MultiLineString else Point(x[0].coords[0]))\n",
    "    rwps = hrd.apply(lambda x: Point(x.coords[0]) if type(x) != MultiLineString else Point(x.geoms[0].coords[0]))\n",
    "    #print(rwps)\n",
    "    \n",
    "    wrk_place = pd.DataFrame()\n",
    "    #print(wrk_point)\n",
    "    if len(wrk_point) > 0:\n",
    "        temp = wrk_point.unstack().dropna().reset_index(drop=True)\n",
    "        wrk_place = pd.concat([rwps, temp])\n",
    "        #wrk_place = rwps.append(wrk_point.unstack().dropna().reset_index(drop=True))\n",
    "    else:\n",
    "        wrk_place = rwps\n",
    "    wrk_place = wrk_place.sample(n = tract.WP_CNT,replace=True).reset_index(drop=True)\n",
    "    wrk_place.index = tract.name + 'w' + wrk_place.index.to_series().astype(str)\n",
    "    #print(\"workplace\")\n",
    "    #print(wrk_place)'\n",
    "\n",
    "    return gpd.GeoSeries(wrk_place)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.7 Main synthesize function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize(tract, od, road, errors, population, wps):\n",
    "    start_time = timeit.default_timer()\n",
    "    #print(tract.name,'started...',end=' ')\n",
    "    try:\n",
    "        people = create_individuals(tract)\n",
    "        #print(people)\n",
    "        create_households(tract,people)\n",
    "        #print(people)\n",
    "        assign_workplaces(tract,people,od)\n",
    "        #create home loaction\n",
    "        houses = create_home_location(tract, people.hhold.nunique(), road)\n",
    "        #create work location\n",
    "        workplaces = create_work_location(tract, road)\n",
    "        #houses, wp = create_spaces(tract, people.hhold.nunique(), od, road)\n",
    "        people['geometry'] = people.hhold.map(houses)\n",
    "        err = get_errors(tract,people)\n",
    "    \n",
    "        #population = pd.concat([population, people])\n",
    "        population.append(people)\n",
    "        #print(population)\n",
    "        wps.append(workplaces)\n",
    "        #wps = pd.concat([wps, workplaces])\n",
    "        #print(wps)\n",
    "        errors.append(err)\n",
    "        #errors = pd.concat([errors, err])\n",
    "    except:\n",
    "        print(tract.name,\" has problems\")\n",
    "        fd = open('Results/problematic_tracts.csv','a')\n",
    "        fd.write(tract.name)\n",
    "        fd.close()\n",
    "    #print(tract.name,'now ended ({:.1f} secs)'.format(timeit.default_timer() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4, Apply above functions to generate Population"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.1, Test Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#list to hold population\n",
    "population = []\n",
    "#hold error\n",
    "errors = []\n",
    "#hold workplaces info\n",
    "wps = []\n",
    "\n",
    "print(\"Start Wokring...\")\n",
    "\n",
    "#set timer\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "#Test Code\n",
    "data = dp[:5]\n",
    "#data = dp[:1000]\n",
    "\n",
    "data.apply(lambda t: synthesize(t,od,road, errors, population, wps),axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4.2, Main Apply-generate Population"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(dp)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    #list to hold population\n",
    "    population = []\n",
    "    #hold error\n",
    "    errors = []\n",
    "    #hold workplaces info\n",
    "    wps = []\n",
    "\n",
    "    print(\"Start Wokring...\")\n",
    "\n",
    "    #set timer\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    #Test Code\n",
    "    data = dp\n",
    "\n",
    "    data.apply(lambda t: synthesize(t,od,road, errors, population, wps),axis=1)\n",
    "\n",
    "    #Hold the resutls in pickles for later ectraction, which will save memory\n",
    "    with open('results/'+\"errors\"+\"erie\"+\".pkl\", 'wb') as f:\n",
    "        pickle.dump(errors, f)\n",
    "    with open('results/'+\"population\"+\"erie\"+\".pkl\", 'wb') as f:\n",
    "        pickle.dump(population, f)\n",
    "    with open('results/'+\"wps\"+\"erie\"+\".pkl\", 'wb') as f:\n",
    "        pickle.dump(wps, f)\n",
    "\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    print(\"Total Time(s):\", elapsed)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Data extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CollectResultsPop(results, X):\n",
    "    if X == \"Pop\":\n",
    "        print(\"Population\")\n",
    "        temp_df = pd.DataFrame()\n",
    "        for i in results:\n",
    "            temp_df = pd.concat([temp_df,i])\n",
    "\n",
    "        temp_df = temp_df.reset_index().drop(['code'], axis=1)\n",
    "        temp_df.rename(columns={temp_df.columns[0]: 'id'},inplace=True)\n",
    "        print(temp_df.head())\n",
    "\n",
    "        final_df = gpd.GeoDataFrame(temp_df, geometry='geometry')\n",
    "        final_df['long'] = final_df['geometry'].x\n",
    "        final_df['lat'] = final_df['geometry'].y\n",
    "        print(\"=====GP Data=====\")\n",
    "        print(final_df.head())\n",
    "        return final_df #return pandas df with geometry\n",
    "    \n",
    "    if X == \"Work\":\n",
    "        print(\"Work\")\n",
    "        wp  = pd.DataFrame()\n",
    "        for j in results:\n",
    "            wp = pd.concat([wp,j])\n",
    "            #wp = wp.append(j, ignore_index=True)\n",
    "        wp = wp.reset_index()\n",
    "        wp.rename(columns={wp.columns[0]: 'wp', wp.columns[1]: 'geometry'},inplace=True)\n",
    "        \n",
    "        print(\"=====Work Data=====\")\n",
    "        print(wp.head())\n",
    "        return wp\n",
    "    \n",
    "    else:\n",
    "        #Errors\n",
    "        print(\"Error\")\n",
    "        er = pd.DataFrame()\n",
    "        for e in results:\n",
    "            #print(e)\n",
    "            er = pd.concat([er,e])\n",
    "        #print(er.head())\n",
    "        return er"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pop = CollectResultsPop(population, \"Pop\")\n",
    "work = CollectResultsPop(wps, \"Work\")\n",
    "err = CollectResultsPop(errors, \"Er\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.to_csv('results/erie_population.csv')\n",
    "work.to_csv('results/erie_workplaces.csv')\n",
    "#err = CollectResultsPop(errors, \"Er\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(pop)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop.wp.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.wp.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.age>= 18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Workplaces\n",
    "wp  = pd.DataFrame()\n",
    "for j in wps:\n",
    "    wp = pd.concat([wp,j])\n",
    "    #wp = wp.append(j, ignore_index=True)\n",
    "wp = wp.reset_index()\n",
    "wp.rename(columns={wp.columns[0]: 'wp', wp.columns[1]: 'geometry'},inplace=True)\n",
    "wp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wp.to_csv('workplace_NY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Errors\n",
    "er = pd.DataFrame()\n",
    "for e in errors:\n",
    "    print(e)\n",
    "    er = pd.concat([er,e])\n",
    "er.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4.2, Save files\n",
    "df.to_csv('full_population.csv')\n",
    "wp.to_csv('full_workplaces.csv')\n",
    "er.to_csv('full_errors.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
